{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPHxKQ2yPNEP9uJ8ItJ0x1I"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"s855E5pDgxDW"},"outputs":[],"source":["import pickle\n","import numpy as np\n","import pandas as pd\n","import joblib\n","import librosa\n","import os\n","import resampy\n","import time"]},{"cell_type":"code","source":["#!pip3 install pydub numpy python_speech_features\n"],"metadata":{"id":"0Yd3Dl_cAIQ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#!pip install resampy\n","#!pip install scikit-learn==1.2.1\n"],"metadata":{"id":"66FBvyaDm1iS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load model"],"metadata":{"id":"j7y_ZwD9kXio"}},{"cell_type":"code","source":["# Load the trained model\n","with open('emotion_model.joblib', 'rb') as file:\n","    model = joblib.load(file)\n"],"metadata":{"id":"Rohn-q2Dhd1n"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["feature extraction"],"metadata":{"id":"K2K-A_e5kV33"}},{"cell_type":"code","source":["def extract_feature(file_name, mfcc=True):\n","    try:\n","        # Load the audio file\n","        X, sample_rate = librosa.load(os.path.join(file_name), res_type='kaiser_fast')\n","\n","        # Initialize result with MFCC features if enabled\n","        result = np.array([])\n","        if mfcc:\n","            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sample_rate, n_mfcc=40).T, axis=0)\n","            result = np.hstack((result, mfccs)) if result.size else mfccs  # Initialize or stack\n","\n","        return result\n","    except Exception as e:\n","        print(f\"Error processing file {file_name}: {e}\")\n","        return None\n"],"metadata":{"id":"fOWlp_r9kVFT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pydub import AudioSegment\n","import numpy as np\n","from python_speech_features import mfcc\n","\n","def extract_feature(file_name, extract_mfcc=True):  # Renamed the flag to avoid conflict with the function name\n","    try:\n","        # Load audio file using pydub\n","        audio = AudioSegment.from_wav(file_name)\n","\n","        # Convert audio to mono and normalize sample rate to 16000 Hz\n","        audio = audio.set_channels(1).set_frame_rate(16000)\n","\n","        # Get raw data from audio and convert to numpy array\n","        samples = np.array(audio.get_array_of_samples())\n","\n","        # Initialize result with MFCC features if enabled\n","        result = np.array([])\n","\n","        if extract_mfcc:  # Check if MFCC extraction is enabled\n","            # Reshape the samples to be 2D, as required by the mfcc function\n","            samples_reshaped = np.reshape(samples, (-1, 1))  # Reshaping to 2D array\n","\n","            # Extract MFCC features using python_speech_features\n","            mfcc_features = mfcc(samples_reshaped, samplerate=16000, numcep=40)\n","\n","            # Get mean of MFCC features across time axis\n","            mfcc_mean = np.mean(mfcc_features, axis=0)\n","\n","            # Stack the MFCC mean with the result\n","            result = np.hstack((result, mfcc_mean)) if result.size else mfcc_mean\n","\n","        return result\n","    except Exception as e:\n","        print(f\"Error processing file {file_name}: {e}\")\n","        return None\n"],"metadata":{"id":"9IlEm8Sa_-WR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["start = time.time()\n","feature=extract_feature(\"03-01-07-02-02-02-01.wav\", True)\n","end = time.time()\n","print(end-start)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4yN6Y0GllBKz","executionInfo":{"status":"ok","timestamp":1736005021219,"user_tz":-120,"elapsed":341,"user":{"displayName":"Haya A.K","userId":"06681843229145100159"}},"outputId":"3c80188b-39bb-4570-8477-ca34f9066869"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["0.027511119842529297\n"]}]},{"cell_type":"code","source":["if feature is not None:\n","    # Ensure the feature is 2D for model prediction\n","    feature_2d = np.array([feature])  # Convert to 2D array\n","\n","    # Make a prediction\n","    predictions = model.predict(feature_2d)\n","\n","    print(\"Predicted Output:\", predictions)\n","else:\n","    print(\"Feature extraction failed.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":369},"id":"mY_gP2PplW5j","executionInfo":{"status":"error","timestamp":1736005021219,"user_tz":-120,"elapsed":4,"user":{"displayName":"Haya A.K","userId":"06681843229145100159"}},"outputId":"12443a89-a2fa-42a5-f531-3cc4eb15a676"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"X has 26 features, but StandardScaler is expecting 40 features as input.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-312eb41297bd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Make a prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_2d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Predicted Output:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, **params)\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_routing_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    784\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwith_final\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 785\u001b[0;31m                     \u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    786\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1062\u001b[0;31m         X = validate_data(\n\u001b[0m\u001b[1;32m   1063\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2964\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2965\u001b[0;31m         \u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_estimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2967\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(estimator, X, reset)\u001b[0m\n\u001b[1;32m   2827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   2830\u001b[0m             \u001b[0;34mf\"X has {n_features} features, but {estimator.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m             \u001b[0;34mf\"is expecting {estimator.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: X has 26 features, but StandardScaler is expecting 40 features as input."]}]}]}